{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CellCycleLifting Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules.io.load.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m root_folder \u001b[38;5;241m=\u001b[39m rootutils\u001b[38;5;241m.\u001b[39mfind_root()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01momegaconf\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphLoader\n",
      "File \u001b[0;32m~/Documents/TopoProjectX/challenge-icml-2024/modules/io/load/loaders.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momegaconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictConfig\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AbstractLoader\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Preprocessor\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msplit_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     assing_train_val_test_mask_to_graphs,\n\u001b[1;32m     14\u001b[0m     load_graph_cocitation_split,\n\u001b[1;32m     15\u001b[0m     load_graph_tudataset_split,\n\u001b[1;32m     16\u001b[0m     load_split,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     load_cell_complex_dataset,\n\u001b[1;32m     20\u001b[0m     load_hypergraph_pickle_dataset,\n\u001b[1;32m     21\u001b[0m     load_simplicial_dataset,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/TopoProjectX/challenge-icml-2024/modules/io/preprocessor/preprocessor.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhydra\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ensure_serializable, make_hash\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPreprocessor\u001b[39;00m(torch_geometric\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mInMemoryDataset):\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Preprocessor for datasets.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m        Additional arguments.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modules.io.load.utils'"
     ]
    }
   ],
   "source": [
    "import rootutils\n",
    "import json\n",
    "\n",
    "rootutils.setup_root(\"./\", indicator=\".project-root\", pythonpath=True)\n",
    "root_folder = rootutils.find_root()\n",
    "import omegaconf\n",
    "from modules.io.load.loaders import GraphLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either we keep yaml config files and provide a brief overview of them, or we build the required config files by hand in these tutorials. (I prefer the former option.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"manual_dataset\"\n",
    "dataset_config = omegaconf.OmegaConf.load(\n",
    "    f\"{root_folder}/configs/dataset/{dataset_name}.yaml\"\n",
    ").parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print dataset config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data_domain\": \"graph\",\n",
      "    \"data_type\": \"manual_dataset\",\n",
      "    \"data_name\": \"manual\",\n",
      "    \"data_dir\": \"/Users/gbg141/Documents/TopoProjectX/challenge-icml-2024/datasets/graph/manual_dataset\",\n",
      "    \"num_features\": 1,\n",
      "    \"num_classes\": 2,\n",
      "    \"task\": \"classification\",\n",
      "    \"loss_type\": \"cross_entropy\",\n",
      "    \"monitor_metric\": \"accuracy\",\n",
      "    \"task_level\": \"node\",\n",
      "    \"split_type\": \"k-fold\",\n",
      "    \"k\": 10,\n",
      "    \"data_seed\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print config file for nice visualization\n",
    "dict2print = dataset_config.copy()\n",
    "print(json.dumps(dict(dict2print), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Transform Config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same dilemma as before, yaml files or dicts within tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lifting type\n",
    "lifting_type = \"graph2cell\"\n",
    "\n",
    "# Define lifting id (name)\n",
    "id_lifting = \"cell_cycle\"\n",
    "\n",
    "# Read yaml file\n",
    "transform_config = {\n",
    "    \"lifting\": omegaconf.OmegaConf.load(\n",
    "        f\"{root_folder}/configs/transforms/topological_liftings/{lifting_type}/{id_lifting}.yaml\"\n",
    "    )\n",
    "    # other transforms (e.g. data manipulations, feature liftings) can be added here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print transform config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"lifting\": {\n",
      "        \"_target_\": \"modules.transforms.data_transform.DataTransform\",\n",
      "        \"complex_dim\": 3,\n",
      "        \"feature_lifting\": \"SumLifting\",\n",
      "        \"k_value\": 1,\n",
      "        \"max_cell_length\": null,\n",
      "        \"preserve_edge_attr\": false,\n",
      "        \"transform_name\": \"CellCycleLifting\",\n",
      "        \"transform_type\": \"lifting\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print config file for nice visualization\n",
    "dict2print = transform_config.copy()\n",
    "dict2print[\"lifting\"] = dict(dict2print[\"lifting\"])\n",
    "\n",
    "print(json.dumps(dict(dict2print), sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform parameters are the same, using existing data_dir: /Users/gbg141/Documents/TopoProjectX/challenge-icml-2024/datasets/graph/manual_dataset/manual/lifting/3481276899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/topox/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:301: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "dataset = GraphLoader(dataset_config, transform_config).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from modules.io.utils.utils import plot_manual_graph\n",
    "# plot_manual_graph(dataset.data)\n",
    "# DONE FOR SIMPLICIAL COMPLEXES; Shall we do smth similar with cells and hypergraphs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topomodelx.nn.cell.cwn import CWN\n",
    "import torch\n",
    "\n",
    "\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels_0,\n",
    "        in_channels_1,\n",
    "        in_channels_2,\n",
    "        hidden_channels,\n",
    "        out_channels,\n",
    "        n_layers=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.base_model = CWN(\n",
    "            in_channels_0,\n",
    "            in_channels_1,\n",
    "            in_channels_2,\n",
    "            hidden_channels,\n",
    "            n_layers,\n",
    "        )\n",
    "        self.linear_0 = torch.nn.Linear(hidden_channels, out_channels)\n",
    "        self.linear_1 = torch.nn.Linear(hidden_channels, out_channels)\n",
    "        self.linear_2 = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_0, x_1, x_2 = self.base_model(\n",
    "            data.x_0,\n",
    "            data.x_1,\n",
    "            data.x_2,\n",
    "            data.adjacency_1,\n",
    "            data.incidence_2,\n",
    "            data.incidence_1.T,\n",
    "        )\n",
    "        x_0 = self.linear_0(x_0)\n",
    "        x_1 = self.linear_1(x_1)\n",
    "        x_2 = self.linear_2(x_2)\n",
    "        return x_0, x_1, x_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 2\n",
    "in_channels_0 = dataset_config[\"num_features\"]\n",
    "in_channels_1 = dataset_config[\"num_features\"]\n",
    "in_channels_2 = dataset_config[\"num_features\"]\n",
    "hidden_channels = 32\n",
    "out_channels = dataset_config[\"num_classes\"]\n",
    "\n",
    "model = Network(\n",
    "    in_channels_0=in_channels_0,\n",
    "    in_channels_1=in_channels_1,\n",
    "    in_channels_2=in_channels_2,\n",
    "    hidden_channels=hidden_channels,\n",
    "    out_channels=out_channels,\n",
    "    n_layers=n_layers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for simplicity and visualization reason we utilised simple graph, however there is a set of available datasets that you can play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    # Working datasets:\n",
    "    # \"cocitation_cora\",\n",
    "    # \"cocitation_citeseer\",\n",
    "    # \"cocitation_pubmed\",\n",
    "    # \"MUTAG\",\n",
    "    # \"NCI1\",\n",
    "    # \"NCI109\",\n",
    "    # Something is wrong with the following datasets:\n",
    "    # \"IMDB-BINARY\",\n",
    "    # \"IMDB-MULTI\",\n",
    "    # \"REDDIT-BINARY\",\n",
    "]\n",
    "for dataset_name in dataset_names:\n",
    "    dataset_config = omegaconf.OmegaConf.load(\n",
    "        f\"{root_folder}/configs/dataset/{dataset_name}.yaml\"\n",
    "    ).parameters\n",
    "\n",
    "    dataset = GraphLoader(dataset_config, transform_config).load()\n",
    "\n",
    "# Define lifting type\n",
    "# lifting_type = \"graph2simplicial\"\n",
    "\n",
    "# # Define lifting id (name)\n",
    "# id_lifting = \"simplicial_clique\"\n",
    "\n",
    "# # Read yaml file\n",
    "# transform_config = {\n",
    "#     \"lifting\": omegaconf.OmegaConf.load(\n",
    "#         f\"{root_folder}/configs/transforms/topological_liftings/{lifting_type}/{id_lifting}.yaml\"\n",
    "#     )\n",
    "#     # other transforms (e.g. data manipulations, feature liftings) can be added here\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
